robot:
  
  # The USB port where the AL5D robot is connected on this particular computer.
  # alternatives: linux: /dev/ttyUSB0, /dev/ttyUSB1
  usb_port: "/dev/ttyUSB0"

  # The camera numbers which should be used for the robot, as a list
  # Typically 0 is the webcam of the computer, other ones in the order they are connected
  active_camera_list: [2]

  ## Size of the latent encoding
  ## FIXME: in the case of the Conv-VAE, this number must be the same as the one
  ## in the conf-robot-machinename.json, latent_dims
  latent_encoding_size: 128


demos:

  # Data directory for demonstrations. This is where demonstrations are saved, or loaded from in the case of replay
  directory: "/path/to/the/directory/of/demonstrations"

training:
  # Data directory for training data. This is where the training data is kept and organized 
  directory: "."

conv_vae:
  # Directory for the checkout of the CONV_VAE project 
  # https://github.com/julian-8897/Conv-VAE-PyTorch
  code_dir: 'path/to/checkout/Julian-8897-Conv-VAE-PyTorch/Conv-VAE-PyTorch'
  # The json file which is going to be used as the starting point
  json_template: '/path/to/the/json/file'
  # The name of the model that is used in the JSON file 
  model_name: 'VAE_Robot'
  model_dir: '/path/to/where/to/store/the/model/VisionBasedRobotManipulator-models/Conv-VAE/'
  model_file: 'path/to/checkpoint/to/use/checkpoint-epoch20.pth'
  training_data_dir: 'path/to/training/data/dir/vae-training-data'   